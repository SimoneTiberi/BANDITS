---
title: "BANDITS: Bayesian ANalysis of DIfferenTial Splicing"
author: "Simone Tiberi and Mark D. Robinson"
date: "`r format(Sys.Date(), '%m/%d/%Y')`"
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: true
    fig_width: 6
bibliography: References.bib
vignette: >
  %\VignetteIndexEntry{BANDITS: Bayesian ANalysis of DIfferenTial Splicing}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\usepackage[utf8]{inputenc}
---

```{r setup, echo=FALSE, results="hide"}
knitr::opts_chunk$set(tidy=FALSE, cache=TRUE,
dev="png",
message=TRUE, error=FALSE, warning=TRUE)
```

# Abstract
*BANDITS* is a Bayesian hierarchical method to perform differential splicing via differential transcript usage (DTU).
*BANDITS* uses a hierarchical structure, via a Dirichlet-Multinomial model, to explicitly model the over-dispersion between replicates and allowing for sample-specific transcript relative abundance (i.e., the proportions).
We input the equivalence classes and respective counts, where the equivalence classes represent the group of transcripts reads are compatible with.
The method is embedded in a Bayesian hierarchical framework, where the posterior densities of the parameters are inferred via Markov chain Monte Carlo (MCMC) techniques.
The allocation of each RNA-seq read to its transcript of origin is treated as a latent variable and also sampled in the MCMC.
To test for DTU, we compare the average transcript relative abundance between two or more conditions.
A statistical test is performed, both, at the gene and transcript level, allowing scientists to investigate what specific transcripts are differentially used in significant genes.
*BANDITS* package version: `r packageVersion("BANDITS")`

Use `browseVignettes("BANDITS")` to access the R code used in the vignettes.

Questions relative to *BANDITS* should be written to the *[Bioconductor support site](https://support.bioconductor.org)*, tagging the question with "BANDITS".

# Aligning reads
The package inputs the equivalence classes and respective counts.
These can be obtained by aligning reads either directly to a reference transcriptome with pseudo-alignmers, such as *salmon* [@salmon] or *kallisto* [@kallisto], or to a reference genome with splice-aware genome alignment algorithms, such as *STAR* [@STAR] or *TopHat2* [@TopHat2], and checking the transcripts compatible with each genome alignment (e.g., via *salmon*).

NOTE: currently *BANDITS* only inputs equivalence classes computed from *salmon*.
We are extending our current framework to allows reads to be aligned with *kallisto*.

Importantly, when using *salmon*, use the option `--dumpEq` to obtain the equivalence classes, and when using *STAR*, use the option `--quantMode TranscriptomeSAM` to obtain alignments translated into transcript coordinates.

The file [README](https://github.com/SimoneTiberi/BANDITS/blob/master/README.md) provides two pipelines to align reads.

# Gene-transcript matching
Further to the equivalence classes, our tool requires the matching between transcript and gene ids, compatible with the genome or transcriptome used to align reads.
There are multiple ways to compute a gene-transcript compatibility matrix; below we show two examples to create it, accoriding to whether reads are aligned with a genome and transcriptome aligner.
Bear in mind that the example code below will not work on any given gtf and fasta file and adjustments might be needed; alternative approaches to compute gene-transcript matchings are illustrated in *tximport* [@tximport] vignette.

If the reads are aligned to the genome first, we can compute a gene-transcript association from the gtf file via *GenomicFeatures* [@GenomicFeatures] library.
Here we provide an example code:
```{r eval=FALSE} 
suppressMessages(library(GenomicFeatures))
gtf_file = system.file("extdata","GTF_files","Aedes_aegypti.partial.gtf",
                       package="GenomicFeatures")
tx = as.list(makeTxDbFromGFF(gtf_file) )
ss = unlist(transcriptsBy(tx, by="gene"))
gene_tr_id_gtf = data.frame(gene_id = names(ss), 
                            transcript_id = ss$tx_name )
gene_tr_id_gtf = gene_tr_id_gtf[ rowSums( is.na(gene_tr_id_gtf)) == 0, ] # remove eventual NA's
gene_tr_id_gtf = unique(gene_tr_id_gtf) # remove eventual duplicated rows

```

If the reads are aligned directly to the transcriptome, we compute a gene-transcript association from the cDNA fasta file via *Biostrings* [@Biostrings] library.
Here we provide an example code:
```{r eval=FALSE} 
suppressMessages(library(Biostrings))
data_dir = system.file("extdata", package = "BANDITS")
fasta = readDNAStringSet(file.path(data_dir, 
                                   "Homo_sapiens.GRCh38.cdna.all.1.1.10M.fa.gz"))
ss = strsplit(names(fasta), " ")
gene_tr_id_fasta = data.frame(gene_id = gsub("gene:", "", sapply(ss, .subset, 4)),
                              transcript_id = sapply(ss, .subset, 1))
gene_tr_id_fasta = gene_tr_id_fasta[ rowSums( is.na(gene_tr_id_fasta)) == 0, ] # remove eventual NA's
gene_tr_id_fasta = unique(gene_tr_id_fasta) # remove eventual duplicated rows
```

# DTU pipeline

Load the \Rpackage{BANDITS} package.
```{r}
library(BANDITS)
```

## Preliminary information
Specify the directory of the data (internal in the package).
```{r}
data_dir = system.file("extdata", package = "BANDITS")
```

We need a matrix or data.frame containing the matching between the transcript and the gene identifiers.
The file ``alignment and gene-transcript matching.txt'' shows how to create such a file from a gtf (in case of genome alignment) or from a fasta file (in case of transcript alignment).

Load the precomputed gene-transcript matching.
`gene_tr_id` is a data.frame (but a matrix is also accepted) containing the transcripts ids on the second column and the corresponding gene ids on the first column.
```{r}
data("gene_tr_id", package = "BANDITS")
head(gene_tr_id)
```

Specify the directory of the transcript level estimated counts.
```{r}
sample_names = paste0("sample", seq_len(4))
quant_files = file.path(data_dir, sample_names, "quant.sf")
file.exists(quant_files)
```

Load the transcript level estimated counts via tximport; in our case counts were aligned with *salmon*, but other tools are also accepted (e.g., *kallisto*).
```{r}
library(tximport)
txi = tximport(files = quant_files, type = "salmon", txOut = TRUE)
counts = txi$counts
head(counts)
```

We define the design of the study: in our case we have 2 groups, that we call "A" and "B" of 2 samples each.
```{r}
samples_design = data.frame(sample_id = sample_names,
                            group = c("A", "A", "B", "B"))
samples_design
```

The groups are defined in:
```{r}
levels(samples_design$group)
```

## Optional (recommended): transcript pre-filtering
Pre-filtering lowly abundant transcripts was found to improve performance of differential splicing methods;
% REF: charlotte and our work!
furthermore, by simplifying the inferential problem, it also leads to a significant reduction in the computational cost of our method.
Albeit not strictly required, we highly suggest to pre-filter transcripts.
Here, we use a mild filtering cutoff by remove transcripts whose average relative abundance is below 0.01.
For the filtering step, we use transcript-level estimated counts to compute the average relative abundance.

Compute the transcripts to keep, by filtering lowly abundant transcripts.
Here `min_transcript_proportion = 0.01` will remove transctipts with estimated mean relative abundance below 0.01.
We further impose constraints on the total abundance: `min_transcript_counts = 10` indicates that each transcript must have at least 10 estimated counts (adding counts from all samples), and `min_gene_counts = 20` specifies that each gene should have at least 20 estimated counts (adding counts from all samples).
While running, `filter_transcripts` prints on screen the percentage of transcripts and genes kept after filtering: in this case about 81% of the transcripts and 73% of the genes are filtered.
```{r}
transcripts_to_keep = filter_transcripts(gene_to_transcript = gene_tr_id,
                                         transcript_counts = counts, 
                                         min_transcript_proportion = 0.01,
                                         min_transcript_counts = 10, 
                                         min_gene_counts = 20)
head(transcripts_to_keep)
```

## Load the data
Before loading the data, we compute, via `eff_len_compute`, the median effective lenght of each transcript (the median is computed with respect to the samples).
```{r}
eff_len = eff_len_compute(x_eff_len = txi$length)
```

We then specify the path to the equivalence classes in `equiv_classes_files`.
```{r}
equiv_classes_files = file.path(data_dir, sample_names, 
                                "aux_info", "eq_classes.txt")
file.exists(equiv_classes_files)
```

Warning: the sample names in `equiv_classes_files` must have the same order as those in the design object, containted in `samples_design`.
```{r}
equiv_classes_files
samples_design$sample_id
```

We then import the equivalence classes and respective counts, and create a `BANDITS_data` object via `create_data`.
When providing `transcripts_to_keep`, the function filters internally transcripts that are not in the vector.
When filtering transripts, we suggest to parallelize computations and use one core per sample (i.e., `n_cores = length(path_to_eq_classes)`).
Since at least 2 transcripts are necessary to study differential splicing, genes with a single transcript are not analyzed.
```{r}
BANDITS_data = create_data(gene_to_transcript = gene_tr_id,
                           path_to_eq_classes = equiv_classes_files,
                           eff_len = eff_len, n_cores = 2,
                           transcripts_to_keep = transcripts_to_keep)
```

If transcripts pre-filtering is not wanted, do not specify `transcripts_to_keep` parameter.

After loading the data, with `filter_genes(data, min_counts_per_gene = 20)`, we remove genes with less than 20 counts overall (i.e.,  considering all equivalence classes across all samples).
```{r}
BANDITS_data = filter_genes(BANDITS_data, min_counts_per_gene = 20)
```

## Optional (recommended): infer an informative prior for the precision parameter
In this Section we illustrate how to formulate an informative prior for the precision parameter 
(i.e., the Dirichlet-Multinomial parameter modelling the degree of over-dispersion between samples).
Note that this is an optional, yet highly recommended, step.

The `prior_precision` function builds on top of *DRIMSeq*'s [@DRIMSeq] `DRIMSeq::dmPrecision` function which provides genewise estimates of the precision parameter.
Use the same filtering criteria as in `filter_transcripts`; if transcript pre-filtering is not performed, set `min_transcript_proportion`, `min_transcript_counts` and `min_gene_counts` to 0.
```{r}
set.seed(61217)
prec = prior_precision(gene_to_transcript = gene_tr_id,
                       transcript_counts = counts,
                       min_transcript_proportion = 0.01,
                       min_transcript_counts = 10,
                       min_gene_counts = 20, n_cores = 2)
```

The first element of the result contains the mean and standard deviation of the log-precision estimates.
```{r}
prec[[1]]
```

Plot the histogram of the genewise log-precision estimates.
The black solid line represents the normally distributed prior distribution for the log-precision parameter.
```{r}
plot_precision(prec)
```

## Test for DTU
With `test_DTU`, we jointly run the MCMC algorithm, to infer the posterior distributions of the parameters, and test for DTU.
`mean_log_delta` and `sd_log_delta` represent the mean and standard deviation of the informative prior for the log-precision parameter, if available.
If an informative prior was not computed, leave `mean_log_delta` and `sd_log_delta` fields unspecified.

`R` and `burn_in` represent the length of the MCMC chain (excluding the burn-in) and the length of the burn-in (i.e., the initial portion of the chain which is discarded).
For genes that are analyzed together (because one or more reads are compatible with multiple genes), `R` and `burn_in` are doubled to face the increased complexity of the inferential problem.
The method requires at least `R = 10^4` and `burn_in = 2*10^3`.
Albeit no difference was observed in simulation studies when increasing these numbers, we encourage users to possibly use higher values (e.g., double) if the computational time allows it.

A convergence diagnostic is used to test if the posterior chains are stationary and to determine if a further fraction of the chain should be discarded as burn-in.
If convergence is not reached, the chain is discarded and a second chain is run; if convergence is again not reached, a third chain is run: if three consecutive chains fail to converge, the respective gene is not tested for DTU.

It is highly suggested to speed up computations by parallelizing the method and specifying the number of parallel threads via the `n_cores` parameter.
Before running the MCMC, we set the seed for the random number generation in R.

For genes with a p.value below 0.1, `test_DTU` runs a second independent MCMC chain, merges it with the first one and tests again for DTU based on the aggregated chain.

The method can technicall be run with a single observation per group, however 2 in each group should be regarded as the very minimum sample size.

We run the DTU method.
`group_col_name` indicates the name of the column of `samples_design` containing the group id of each sample (by default `group_col_name = "group"`).
```{r}
set.seed(61217)
x = test_DTU(BANDITS_data = BANDITS_data,
             prior_precision = prec$prior,
             samples_design = samples_design,
             group_col_name = "group",
             R = 10^4, burn_in = 2*10^3, n_cores = 2,
             gene_to_transcript = gene_tr_id)
```

The output of `test_DTU` is a `BANDITS_test` object; results are stored in 3 `data.frame` objects containing gene level results, transcript level results and convergence output.
All results are sorted, by default, according to the significance of the gene level test.

To read a full description of the output from `test_DTU`, see `help(BANDITS\_test)`.
```{r}
x
```

Functions `top_genes`, `top_transcripts` and `convergence` can be used to access gene level results, transcript level results and convergence output, respectively.

Visualize the most significant Genes, sorted by gene level significance.
```{r}
head(top_genes(x))
```

Alternatively, gene-level results can also be sorted according to "DTU_measure", which is a measure of the strength of the change between average relative abundances of the two groups.
```{r}
head(top_genes(x, sort_by = "DTU_measure"))
```

Visualize the most significant transcripts, sorted by transcript level significance.
```{r}
head(top_transcripts(x, sort_by = "transcript"))
```

Visualize the convergence output for the most significant genes, sorted by gene level significance.
```{r}
head(convergence(x))
```

We can further use the `gene` function to gather all output for a specific gene: gene level, transcript level and convergence results.
```{r}
top_gene = top_genes(x, n = 1)
gene(x, top_gene$Gene_id)
```

Similarly we can use the `transcript` function to gather all output for a specific transcript.
```{r}
top_transcript = top_transcripts(x, n = 1)
transcript(x, top_transcript$Transcript_id)
```

Finally, we can plot the estimated average transcript relative expression in the two groups for a specific gene via `plot_proportions`.
```{r}
plot_proportions(x, top_gene$Gene_id)
```

# Session info
```{r sessionInfo}
sessionInfo()
```

# References
